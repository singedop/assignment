{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# Accident Severity Probability Prediction in Seattle City\nIBM Coursera Applied Data Science Capstone Project\nSeptember 2022"}, {"metadata": {}, "cell_type": "markdown", "source": "# 1. Problem Introduction\nData to represent road condition that lead to accident is needed for accident severity analysis and prediction. These data could be the the road condition during the accident, the weather, the light condition, the driver condition, etc. From these data, a model could be built to predict the severity of accident if it occurs during that particular road, and driver conditions."}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd\nimport numpy as np", "execution_count": 23, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "\n# 2. Data Acquisition, Selection, and Cleaning"}, {"metadata": {}, "cell_type": "markdown", "source": "Dataset acquired from https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/DP0701EN/version-2/Data-Collisions.csv. The metadata for this dataset can be downloaded in https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/DP0701EN/version-2/Metadata.pdf."}, {"metadata": {}, "cell_type": "code", "source": "df = pd.read_csv(\"file:///C:/Users/popac//date.csv\")\ndf.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df.columns", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "time = df.sort_values(by='INCDATE')\nprint(time['INCDATE'].head(1))\nprint(time['INCDATE'].tail(1))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df = df.dropna(subset=[\"X\"], axis=0)\ndf = df.dropna(subset=[\"Y\"], axis=0)\ndf = df.rename(columns={'X':'LONGITUDE', 'Y':'LATITUDE'})\nprint(df.shape)\ndf.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(df['JUNCTIONTYPE'].value_counts())\nprint(df['JUNCTIONTYPE'].value_counts().sum())\nprint(df['ADDRTYPE'].value_counts())\nprint(df['ADDRTYPE'].value_counts().sum())", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df.columns", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model_df = df[['LATITUDE', 'LONGITUDE', 'ADDRTYPE', 'PERSONCOUNT', 'VEHCOUNT', 'INATTENTIONIND', 'UNDERINFL',\\\n               'WEATHER', 'ROADCOND', 'LIGHTCOND', 'SPEEDING', 'SEVERITYCODE']]\nmodel_df.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "missing_values = model_df.isnull()\nfor column in missing_values.columns.values.tolist():\n    print(column)\n    print (missing_values[column].value_counts())\n    print(\"\")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "clean_df = model_df.copy()\n\nclean_df.dropna(subset=[\"ADDRTYPE\"], axis=0, inplace=True)\nclean_df.reset_index(drop=True, inplace=True)\nclean_df.replace({'INATTENTIONIND' : {'Y' : int(1), np.nan : int(0)},\n                 'SPEEDING' : {'Y' : int(1), np.nan : int(0)},\n                 'UNDERINFL' : {'Y' : int(1), '1' : int(1),\n                                'N' : int(0), '0' : int(0),\n                                np.nan : int(0)}}, inplace=True)\nclean_df['WEATHER'].replace(np.nan, 'Unknown', inplace=True)\nclean_df['ROADCOND'].replace(np.nan, 'Unknown', inplace=True)\nclean_df['LIGHTCOND'].replace(np.nan, 'Unknown', inplace=True)\n\nclean_df.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "EDA_df = clean_df[['WEATHER', 'ROADCOND', 'LIGHTCOND', 'SEVERITYCODE']]\n# drop Unknown and Other data in WEATHER feature\nEDA_df = EDA_df[EDA_df.WEATHER != 'Unknown']\nEDA_df = EDA_df[EDA_df.WEATHER != 'Other']\nprint(EDA_df['WEATHER'].value_counts(), \"\\n\")\n# drop Unknown and Other data in ROADCOND feature\nEDA_df = EDA_df[EDA_df.ROADCOND != 'Unknown']\nEDA_df = EDA_df[EDA_df.ROADCOND != 'Other']\nprint(EDA_df['ROADCOND'].value_counts(), \"\\n\")\n# drop Unknown and Other data in LIGHTCOND feature\nEDA_df = EDA_df[EDA_df.LIGHTCOND != 'Unknown']\nEDA_df = EDA_df[EDA_df.LIGHTCOND != 'Other']\nprint(EDA_df['LIGHTCOND'].value_counts(), \"\\n\")\nprint(EDA_df.shape)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "EDA_df = EDA_df.groupby(['WEATHER', 'ROADCOND', 'LIGHTCOND'])['SEVERITYCODE'].value_counts().to_frame()\nEDA_df = EDA_df.rename(columns={'SEVERITYCODE':'ACC_COUNTS'})\nEDA_df = EDA_df.reset_index()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "EDA_df1 = EDA_df[EDA_df.SEVERITYCODE == 1]\nEDA_df1 = EDA_df1.sort_values(by=['ACC_COUNTS'], ascending=False)\nEDA_df1 = EDA_df1.head(10).reset_index(drop=True)\nEDA_df1['CONDITIONS'] = EDA_df1[['WEATHER','ROADCOND','LIGHTCOND']].agg(', '.join, axis=1)\ncond = EDA_df1['CONDITIONS']\nEDA_df1.drop(labels=['CONDITIONS', 'WEATHER', 'ROADCOND', 'LIGHTCOND', 'SEVERITYCODE'], axis=1, inplace=True)\nEDA_df1.insert(0, 'CONDITIONS', cond)\nEDA_df1", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%matplotlib inline \n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nlabels = EDA_df1['CONDITIONS'].to_list()\n\nax = EDA_df1.plot(kind='bar', stacked=False, width=0.8, figsize=(20,8), fontsize=14)\n\nax.set_title(\"Condition During Accident that Lead to Property Damage in Seattle City\", size=16)\nax.set_xticks(np.arange(0, 10, 1))\nax.set_xticklabels(labels)\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.annotate(\"{:,}\".format(height), xy=(p.get_x() + p.get_width() / 2, height),\n                xytext=(3, 3), textcoords=\"offset points\", \n                ha='center', va='bottom', fontsize=14)\n\nax.legend([])\nax.set_ylabel(\"Number of Accidents\", size=14)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.get_yaxis().set_ticks([])\n\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "EDA_df2 = EDA_df[EDA_df.SEVERITYCODE == 2]\nEDA_df2 = EDA_df2.sort_values(by=['ACC_COUNTS'], ascending=False)\nEDA_df2 = EDA_df2.head(10).reset_index(drop=True)\nEDA_df2['CONDITIONS'] = EDA_df2[['WEATHER','ROADCOND','LIGHTCOND']].agg(', '.join, axis=1)\ncond = EDA_df2['CONDITIONS']\nEDA_df2.drop(labels=['CONDITIONS', 'WEATHER', 'ROADCOND', 'LIGHTCOND', 'SEVERITYCODE'], axis=1, inplace=True)\nEDA_df2.insert(0, 'CONDITIONS', cond)\nEDA_df2", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "labels = EDA_df2['CONDITIONS'].to_list()\n\nax = EDA_df2.plot(kind='bar', stacked=False, width=0.8, figsize=(20,8), fontsize=14)\n\nax.set_title(\"Condition During Accident that Lead to Injury in Seattle City\", size=16)\nax.set_xticks(np.arange(0, 10, 1))\nax.set_xticklabels(labels)\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.annotate(\"{:,}\".format(height), xy=(p.get_x() + p.get_width() / 2, height),\n                xytext=(3, 3), textcoords=\"offset points\", \n                ha='center', va='bottom', fontsize=14)\n\nax.legend([])\nax.set_ylabel(\"Number of Accidents\", size=14)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.get_yaxis().set_ticks([])\n\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(clean_df.shape)\nprint(\"Unique values in feature 'ADDTYPE':\", clean_df['ADDRTYPE'].unique())\nprint(\"Unique values in feature 'WEATHER':\", clean_df['WEATHER'].unique())\nprint(\"Unique values in feature 'ROADCOND':\", clean_df['ROADCOND'].unique())\nprint(\"Unique values in feature 'LIGHTCOND':\", clean_df['LIGHTCOND'].unique())", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "clean_df.replace({'WEATHER' : {'Other' : 'Unknown'},\n                 'ROADCOND' : {'Other' : 'Unknown'},\n                 'LIGHTCOND' : {'Other' : 'Unknown'}}, inplace=True)\nprint(\"Unique values in feature 'ADDTYPE':\", clean_df['ADDRTYPE'].unique())\nprint(\"Unique values in feature 'WEATHER':\", clean_df['WEATHER'].unique())\nprint(\"Unique values in feature 'ROADCOND':\", clean_df['ROADCOND'].unique())\nprint(\"Unique values in feature 'LIGHTCOND':\", clean_df['LIGHTCOND'].unique())", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "X = clean_df.iloc[:, 1:-1]\nprint(X.head())\nprint(X.shape)\ny = clean_df[['LATITUDE', 'LONGITUDE', 'SEVERITYCODE']]\nprint(y.head())\nprint(y.shape)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train_loc, y_test_loc = train_test_split(X, y, test_size=0.3, random_state=9)\nprint ('Train set:', X_train.shape,  y_train_loc.shape)\nprint ('Test set:', X_test.shape,  y_test_loc.shape)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "y_train = y_train_loc['SEVERITYCODE'].values\ny_test = y_test_loc['SEVERITYCODE'].values\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn import preprocessing\nX_train = preprocessing.StandardScaler().fit(X_train).transform(X_train)\nX_test = preprocessing.StandardScaler().fit(X_test).transform(X_test)\nprint(X_train.shape)\nprint(X_train[0:3])\nprint(X_test.shape)\nprint(X_test[0:3])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\n\nLR_Class = LogisticRegression(C=0.01, solver='lbfgs').fit(X_train,y_train)\nyhat_LR = LR_Class.predict(X_test)\nyhat_LR_proba = LR_Class.predict_proba(X_test)\n\nLR_accu = jaccard_similarity_score(y_test, yhat_LR)\nLR_f1 = f1_score(y_test, yhat_LR, average='weighted')\nLR_logloss = log_loss(y_test, yhat_LR_proba)\n\nprint(\"Jaccard similarity index = %.4f\" % LR_accu)\nprint(\"f1-score = %.4f\" % LR_f1)\nprint(\"Logaritmic Loss = %.4f\" % LR_logloss)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.metrics import classification_report, confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\n%matplotlib inline\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, yhat_LR, labels=[2,1])\nnp.set_printoptions(precision=3)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['injury=2','damage=1'],normalize= False,  title='Confusion matrix')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "yhat_prob_df = pd.DataFrame(yhat_LR_proba)\nyhat_prob_df = yhat_prob_df.head(100)\nyhat_prob_df.rename(columns={0:'PROP_DAMAGE', 1:'INJURY'}, inplace=True)\nprint(yhat_prob_df.shape)\nyhat_prob_df.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "y_test_df = pd.DataFrame(y_test_loc)\ny_map = clean_df.iloc[y_test_df.index].copy().head(100)\nprint(y_map.shape)\ny_map.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "y_map['PROP_DAMAGE'] = yhat_prob_df['PROP_DAMAGE'].values\ny_map['INJURY'] = yhat_prob_df['INJURY'].values\nprint(y_map.shape)\ny_map.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "road_type = list(y_map.ADDRTYPE)\nweather = list(y_map.WEATHER)\nroad_cond = list(y_map.ROADCOND)\nlight = list(y_map.LIGHTCOND)\ndamage = list(y_map.PROP_DAMAGE)\ninjury = list(y_map.INJURY)\nlabels = []\n\nfor i, lbl in enumerate(road_type):\n    temp_lbl = \"Road Type: \" + str(lbl) + \"; \" +\\\n                \"Weather: \" + str(weather[i]) + \"; \" +\\\n                \"Road Cond.: \" + str(road_cond[i]) + \"; \" +\\\n                \"Light Cond.: \" + str(light[i]) + \"; \" +\\\n                \"Prop. Damage Prob.: \" + str(round(damage[i]*100, 2)) + \"%; \" +\\\n                \"Injury Prob.: \" + str(round(injury[i]*100,2)) + \"%; \"\n    labels.append(temp_lbl)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import folium\nseattle_map = folium.Map(location=[47.608013, -122.335167], zoom_start=11)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# loop through the 100 accidents and add each to the map\nfor lat, lng, label in zip(y_map.LATITUDE, y_map.LONGITUDE, labels):\n    folium.features.CircleMarker(\n        [lat, lng],\n        radius=5, # define how big you want the circle markers to be\n        color='red',\n        fill=True,\n        popup=label,\n        fill_color='orange',\n        fill_opacity=0.6\n    ).add_to(seattle_map)\n\n# show map\nseattle_map", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.12", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}